---
layout: post
title: "알렉스넷 10년 - GPT가 가져온 특이점을 보며 드는 생각들"
tags: [AI,Transformer,GPT]
---
　 OpenAI의 서비스들이 일반인들에게 관심을 끌기 시작하더니, 작년 말 IT 업계 뿐만아니라 산업전반에 있어서 큰 파란을 일으켰던 GPT. 빌게이츠는 ['인터넷 발견이후 중대한 발명'](https://www.gatesnotes.com/The-Age-of-AI-Has-Begun)라며 자신의 블로그에 내용을 포스팅하기도했다. 취업을 하고나선 한동안 딥러닝에는 크게 관심을 두지않았었는데, 그 동안 놓혔었던 이슈들과 신경망 모델의 진척들을 따라가보고 최근 많은 주목을 받고있는 GPT를보며 드는 생각들을 늘여트려본다.
<!--more-->

<hr/>

### **목차**
- [7년전의 사람들](#7년전의-사람들)
- 트랜드
    - [분류](#분류-모델-트랜드)
    - [생성](#생성-모델-트랜드)
    - [순환망](#순환망-모델-트랜드)
- 요즘 사람들
    - [커뮤니티](#요즘-사람들---커뮤니티-반응)
    - [전문가](#요즘-사람들---전문가들의-견해)
- [7년후의 나에게](#7년-후의-나에게)


<hr/>

### **7년전의 사람들**

<p align="center" style="color:gray">
    <img src="/public/img/2023-03-25-gpts-00.jpg" style="border:1px solid #cdcdcd; border-radius:0.3rem"/>
    <span>2016년도 한국고용정보원에서 조사한 자료. 7년이 지난 지금과는 조금 다른 결과가 나올 것 같다</span>
</p>

　인공지능이 이슈가 될 때 마다 가십거리였다. '앞으로 사라질 직업, 사라지지 않을 직업'. 지금 AI들이 보여주는 퍼포먼스를 보고 위 자료에 '(4%)'에 작가와 화가가 있었다는 것을 보면 앞으로의 일은 아무도 모르겠단 것을 느낀다. 7년전에 그런 예측을 하는 사람들 중 나도 그중 하나였다. 그때의 생각과 지금의 생각을 간단하게 정리해봤다.

>
- 단순작업은 당연하고 사람이 직관으로 처리하는건 모조리 대체가능. 한 10년? <br/> **→ 특이점이 분명히 오기도했고 대체됐다는 것이 없다고는 못하지만 내가 생각한 수준은 아직인 것 같다.**
- 획기적인 하드웨어 발전이 있다면 그 '시간'은 단축될 것 <br/> **→ 하드웨어 발전 보다는 신경망 모델에 생각외의 큰 진척이 있었다** <br/>**→ 모델의 파라메터 수가 진짜 말도 안되게 커졌다. 이게 개인이 할 수 있는 수준이야..?**
- 문제는 현재 트랜지스터 발전속도가 더딤 <br/> **→ 무어의 법칙은 얼추 따라가고있다**
- 무어의 법칙은 꾸역꾸역 따라가는듯 보이지만 같은 공간에 회로를 꾸겨넣는게 이젠 슬슬 한계에 온듯 <br/> **→ CPU/GPU의 성능들이 시장 요구치를 못 따라가고있다는 생각은 든다**
- 그래픽카드의 대역폭 문제: GPU RAM 크기의 한계 때문에 효율적으로 학습시키려면 많은 시간이 필요할 것 <br/> **→ PCIe의 대역폭이 제법 많이 늘긴했다**
<p align="center" style="color:gray">
    <span>모델의 발전이 가장 의외였다.</span>
</p>

<hr/>

### **분류 모델 트랜드**
> CNN → [AlexNet(2012)](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) → [VGGNet(2014)](https://arxiv.org/abs/1409.1556), [GoogLeNet(2014)](https://arxiv.org/abs/1409.4842) → [ResNet(2015)](https://arxiv.org/abs/1512.03385) → [DenseNet(2017)](https://arxiv.org/abs/1608.06993), [MobileNet(2017)](https://arxiv.org/abs/1704.04861), [NasNet(2017)](https://arxiv.org/abs/1707.07012) → [EfficientNet(2019)](https://arxiv.org/abs/1905.11946)

<p align="center" style="color:gray">
    <img src="/public/img/2023-03-25-gpts-07.PNG" style="border:1px solid #cdcdcd; border-radius:0.3rem"/>
    <span>신경망 모델의 주요계보와 이미지 분류 정확도 추이 - <a href="https://paperswithcode.com/sota/image-classification-on-imagenet">paperwithcode.com</a> </span>
</p>

　만약 기계학습이 정규교과로 편성된다면 2012년은 역사교과서에 필히 적히는 해일것이다. 이미지넷이라는 이미지 기계 판독 대회는 70%대의 정확도를 가진 모델들이 우수한 성능으로 우승하던 대회였다. 근데 AlexNet이 무려 84.7%이라는 정확도로 ImageNet 2012에서 우승하면서 큰 파란을 일으켰다. 신경망 학습은 등장한지 30여년이 다돼갔지만 제약이 많아 기계학습에선 비주류였었던 것이, 대회 우승으로 기계학습 패러다임을 서포트벡터머신으로부터 가져온 사건이었다.

　컴퓨터비전 분야뿐만아니라 각 산업전반 모든 연구분야에서 산재되어있었던 자신들의 문제들을 신경망 모델로 풀어보기 시작했다. 자연스레 엄청난 투자자본이 흘러들었고 특히 2016년에 알파고가 일반대중에게 알려지면서 그 흐름은 더더욱이 가속됐다.

　10년 동안 꽤 그럴싸한 결과물들을 뽑아내는 모델들이 나왔다. 이미지넷의 Top5 정확도 기준으로 이미 에러율 5%미만의 분류성능을 내고있다. 최근엔 파라메터 개수를 줄여 모바일 디바이스에서도 어렵지않게 구동 할 수 있도록 모델을 구성하는 움직임도 있다. 각 도메인에 맞게 세분화되어 모델링해가는 모양새다.

<hr/>

### **생성 모델 트랜드**
> [GAN (2014)](https://arxiv.org/abs/1406.2661) → [DCGAN (2015)](https://arxiv.org/abs/1511.06434) → [WGAN (2017)](https://arxiv.org/abs/1701.07875), [ProGAN (2017)](https://arxiv.org/abs/1710.10196) → [StyleGAN (2019)](https://arxiv.org/abs/1812.04948) → [StyleGAN2 (2020)](https://arxiv.org/abs/1912.04958)

<p align="center" style="color:gray">
    <img src="/public/img/2023-03-25-gpts-08.PNG" style="border:1px solid #cdcdcd; border-radius:0.3rem"/>
    <span>Context-Encoder.2017 디테일한 부분은 그리지못했다. <br/> 아웃풋(좌), 인풋(우), 아웃풋-확대(가운데) <a href="https://github.com/chillyMind/context_encoder_pytorch">Github 링크</a></span>
</p>
　생성모델도 정말 눈부신 진척들이 있었다. 위 모델을 구현해볼 당시 학습데이터의 크기와 모양에 한계가 있었다. 모든 트레이닝 셋은 정방형이었으며 이미지 크기에 대한 제약도 있었다. 모델 구조에 맞춰 일부를 자르거나 해상력을 낮춰서 학습시키는 방법이 대부분이었다. 그렇게 공부를 해보고나선, 유의미한 생성모델이 나오기까지는 아직 많은 발전과 시간이 필요하겠다는 생각을 했었었다.

　작년 NovelAI 서비스의 출시는 아티스트들 사이에서 꽤나 세간의 화제였었다. StyleGAN2와 GPT를 곁들인 2D일러스트 생성 서비스다. 아래 결과물들이 그것들이다.

<p align="center" style="color:gray">
    <img src="/public/img/2023-03-25-gpts-01.PNG" style="border:1px solid #cdcdcd; border-radius:0.3rem"/>
    <span>StyleGAN2기반 서비스인 NovelAI로 돌려본 결과.</span><br/><span>다소 추상화된 이미지(우측하단)를 인풋으로 넣었더니 흡족할만한 2D 일러스트가 나왔다.</span>
</p>

　정말 놀랍다. 내 생각보다 특이점이 빨리 온 것 같다. 어떻게 구현했는지 논문을 자세히 읽어봐야겠지만 그 짧은(?)시간에 이렇게 상용에 준하는 수준으로 모델이 발전했다는게 믿기지않다. 그 많은 제약사항들을 극복하고, 수많은 시간과 노고를 들여 이런 모델들을 만들고, 결국 과감히 모두에게 그들의 결과물을 공유를 해주시는 업계의 모든분들께 존경을 표하고싶다.

<hr/>


### **순환망 모델 트랜드**
> [RNN (1985)](https://en.wikipedia.org/wiki/Recurrent_neural_network) → [LSTM (1997)](https://www.bioinf.jku.at/publications/older/2604.pdf) → [GRU (2014)](https://arxiv.org/abs/1412.3555) → [Transformer (2017)](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)

　Self-Attention이라는 쿼리-키 관계 모델링을 활용하여 문맥을 파악하는 모델을 제안됐다. 'Attention Is All You Need'라는 제목으로 발표된 Transformer는 정말 주요한 연구토픽으로 주목받았다. 특히 자연어처리에 놀라운 성능을 보여주자 후속연구가 활발히 진행됐다. 지금도 그 후속연구들이 놀라운 결과물들의 논문과 결과물들을 속속들이 발표해내고있다. GPT 시리즈들이 대표적이다.

>- [Taming Transformers for High-Resolution Image Synthesis (aka. Taming Transformers)](https://arxiv.org/abs/2012.09841), CVF 2021
>- [An image is worth 16x16 words: Transformers for image recognition at scale (aka. ViT)](https://arxiv.org/pdf/2010.11929.pdf), ICLR 2021

　AlexNet이 그랬던 것 처럼, 각 산업분야에서 기존의 CNN 신경망 구조로 해결하지 못했던 내용들을 Transformer를 적용해가면서 시도해보고있다. 다만 아직 CNN 만큼의 퍼포먼스는 내지 못하며, 충분한 데이터와 버티컬리하게 파인튜닝이 필요하다는 한계점이 있다.

　최근 학술회에서의 CAD섹션에서는 Transformer 기반의 생성모델 연구들이 많았다. 명령시퀀스를 인풋으로 3D오브젝트를 뽑아내는 연구들이 특히 흥미로웠다. 그외에 2D 스케치로부터 3D 모델을 생성하는 학습 데이터 추출을 위해 3D모델에서 2D 스케치를 생성하는 등의 연구들이 있었다. 아직 상용화할만한 결과물들이 아직은 나오지는 않고있다. 다만 뭔가 근거없는 추측으로는 정말 빠른시일내로 일을 낼 것 같다.

　굵직한 학회들의 올해 일정들이 끝나면 또 어마어마한 것들이 나와있을 것 같다. 일정을 정리해놓는다.

>- AAAI, 2023-02-09 ~ 2023-02-14
- ICLR, 2023-05-01 ~ 2023-05-05
- CVPR, 2023-06-18 ~ 2023-06-22
- ICML, 2023-07-23 ~ 2023-07-29
- ICCV, 2023-10-02 ~ 2023-10-06
- NIPS, 2023-12-10 ~ 2023-12-16


<hr/>

### **요즘 사람들 - 커뮤니티 반응**

　최근 1년간 AI가 보여준 모습들을 보면 나의 옛 생각과는 사뭇 다른 감상들이 들었다. 7년전 알파고때보다 훨씬 파장력이 크고 놀랍다. '이제 곧 컴퓨터와 로봇이 특정산업군에서 사람을 대체하는 시대가 온다'며 다소 감정실린 비관적 전망들이 이해가기도한다. 몇몇 개발자분들은 'IDE와 언어 그리고 프레임웍이 발전했다고 개발자가 사라지진않았고 오히려 양질의 일자리와 많은 개발자들을 공급하게됐다'며 낙관론을 주장한다.

<p align="center" style="color:gray">
    <img src="/public/img/2023-03-25-gpts-03.PNG" style="border:1px solid #cdcdcd; border-radius:0.3rem"/>
    <span>툴의 발전에도 불구하고 3D아티스트들에게 UV언래핑와 Retopology는 여전히 성가신 프로세스다</span>
</p>

　툴의 발전을 간절히 바라는 사람들도있다. 3D아티스트들에게 UV언래핑과 리토폴로지는 정말 성가신 프로세스다. 작년에 릴리즈된 언리얼5에 들어간 나나이트와 루멘은 언래핑과 리토폴로지가 필요없음을 시사했다(사실 이 표현은 마케팅용인 것 같긴하다). 아직 아티스트들이 모델링 프로세스에 자연스럽게 넣기까지는 시간이 좀 걸리겠지만, 생각하기 어려웠던 것들이 실현되고있다. 어쩌면 2D아티스트와 3D아티스트간 경계가 모호해질 수 도 있을 것 같다.


<hr/> 

### **요즘 사람들 - 전문가들의 견해**

　유발 하라리는 인류가 디스토피아를 맞이할 것이라는 극단적인 전망을 한다. 사피엔스 저자로 잘 알려진 유발하라리는 7년전에도 많은 인터뷰를 했었다. 그가 예측한 인류의 미래는 대부분의 노동력이 기계로 대체된 사회이며, 그렇게 사람들의 경제활동이 부족해진 사회는 빈부격차가 격심해지면서 사회구조가 극단적으로 변할것이라했다. 22년도에 EBS에서 촬영한 '위대한 수업'의 유발하라리 인터뷰 영상이 7년전 그가 주장했던 내용들과 크게 다르지않다.

<p align="center" style="color:gray">
    <img src="/public/img/2023-03-25-gpts-06.PNG" onclick="location.href='https://www.youtube.com/watch?v=MYygMVtxy6c';"  width="75%" height="75%" style="border:1px solid #cdcdcd; border-radius:0.3rem;cursor:pointer"/>
    <span>AI로 대체되기 가장 쉬운 직업은? - EBS 위대한수업, 2022</span>
    <br/>
    <span>22년도에 촬영한 유발하라리 인터뷰영상이지만, 16년도에 주장한 내용과 크게 다르지않다</span>
</p>

> 1. 대체하기 쉬운 직업이란?
    - 데이터 분석 업무를 하는 직업이 대체 될 것. 사람이 직접 몸을 써야하는 일들은 남아있게 될 것이다. <br/> (ex) 의사는 없어지더라도 간호사는 남아있을 것이다.
    - 창의력을 발휘하는 직업은 의외로 대체 되기 쉽다. 대부분의 창의력은 패턴을 파악하고 새롭게 조합하는 일인데 이건 AI가 아주 잘하는 것이다.
> 2. 재교육의 필요성
    - AI로인해 많은 직업들이 사라질 것.
    - 다만 한순간에 없어지지는 않는다. 사람들을 끊임없는 재교육을 시켜야한다.
    - 재교육을 받지않으면 '무용계급'으로 전락할텐데, 이들은 정치적 사회적 문제를 초래할 것.
> 3. 기본 소득보다 교육을
    - 기본 소득보다 모든 사람들에게 교육의 기회와 재교육을 시킴으로써 소외되지않도록 해야한다.
    - 타인에게 자신의 삶을 의탁하지않고 자신의 소득으로 사회에서 지위를 얻어 존중받을 수 있도록 한다.


　OpenAI의 CEO, 샘 알트만은 '[AI가 조금은 무섭다](https://www.cnbc.com/2023/03/20/openai-ceo-sam-altman-says-hes-a-little-bit-scared-of-ai.html)'고 인터뷰했다.
> - 집단지성과 창의력 그리고 인류의 의지를 반영
> - 다만 권위주의 정권에 대한 우려를 표함
> - GPT와 같은 모델들이 허위 정보에 사용 될 수 있음
> - 컴퓨터 코드도 작성이 가능하기에 사이버 공격에 사용 될 수 도 있음을 우려
> - 일자리가 잃게 되는 것은 인정. 하지만 더 높은 삶의 질과 수준을 가질 수 있음
> - 사람들은 이러한 기술에 익숙해지기위해 공부하고 적응할 시간이 필요함

　당연하지만 모두가 새로운 기술에 대해서 적응해야한다고 얘기하고있다.

<hr/> 

### **7년 후의 나에게**
　7년전에도 지난 7년동안의 모습들을 보며 미래를 상상해봤었다. 7년전의 나는 지금 어떻게든 자리를 잡기를 기대했었던 것 같다. 근거는 없지만 가볍게 7년후의 미래를 상상해본다.

> - AI는 산업에 쓰일 수 있을만큼 상용화가 됐지만 그 수준의 격차가 더 벌어져 있을 것 같다.
<br/> → 아직도 학습 데이터의 크기와 질이 중요한데 이건 특정기업에 몰려있다. 7년후에도 별반 다르지 않지않을까?
<br/> → IT갈라파고스화된 우리나라는 이런부분에있어 생각보다 괜찮을수도 있을 것 같다.
> - 개발만 잘하는 사람은 시장에서 좋은 가치를 낼 것 같진 않다.<br/> → 좋은 솔루션 아키텍처를 만드는건 AI가 더 잘하지않을까?
> - 정말 7년후는 버티컬리하게 AI를 잘쓰는 사람만이 높은 가치를 받을 것 같다.<br/> → 아무리 거대AI라해도 도메인의 디테일한 부분까지는 알기 어렵지않을까?
> - 대학에선 기계공학이 지금은 주춤하고있지만, 로봇공학도에 대한 수요가 작년 재작년 개발자 수요만큼 필요할 것 같다.<br/> → 유비쿼터스, 디지털 트랜스포메이션, 메타버스 등등 이름바꿔가면서 얘기하지만, 현실의 문제를 풀기에는 그 무언가가 결여되어있는게 아닐까?
> - 지속가능한 경영, 환경문제, 식량문제 등 인류에게 산재돼있던 숙제들이 개개인 목전까지 왔을 것 같다.<br/> → 개발도상국들이 더 이상 세계의 쓰레기장이 되려고 하지않을 것이다. IT기업이 이런문제를 해결하려는 움직임이 있지않을까?

<hr/>
- [1980년 인터넷 발명이후 가장 중대한 진보, Gates Notes, 2023.03.21](https://www.gatesnotes.com/The-Age-of-AI-Has-Begun)
